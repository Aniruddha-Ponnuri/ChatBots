import streamlit as st
import requests
import uuid

# Streamlit app layout
st.title("LLM Chatbot Interface")

# API Endpoint
API_URL = "http://localhost:8000/chat/"

# Initialize session state for chat history and session ID
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

if "session_id" not in st.session_state:
    st.session_state["session_id"] = str(uuid.uuid4())

# User inputs
model_choice = st.selectbox("Choose a model:", ["GPT-4", "GPT-4o", "Groq LLama-3.1"])
prompt = st.text_input("You:", "")

# Display the chat history
st.markdown("### Chat History")
for i, chat in enumerate(st.session_state["chat_history"]):
    if i % 2 == 0:
        st.write(f"You: {chat}")
    else:
        st.write(f"Model: {chat}")

# Generate response when user submits a prompt
if st.button("Send"):
    if prompt:
        # Add the user prompt to the chat history
        st.session_state["chat_history"].append(prompt)

        # Send the request to the API
        response = requests.post(API_URL, json={"prompt": prompt, "model_choice": model_choice}, cookies={"session_id": st.session_state["session_id"]})

        if response.status_code == 200:
            try:
                generated_text = response.json().get("generated_text")
                if generated_text:
                    # Add the model response to the chat history
                    st.session_state["chat_history"].append(generated_text)
                else:
                    st.error("No response generated by the model.")
            except requests.exceptions.JSONDecodeError:
                st.error("Failed to decode JSON response from the server.")
        else:
            st.error(f"Error: {response.status_code} - {response.text}")
    else:
        st.error("Please enter a prompt.")
